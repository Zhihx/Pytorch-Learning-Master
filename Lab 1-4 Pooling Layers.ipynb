{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f275e52",
   "metadata": {},
   "source": [
    "**The link can be found below**\n",
    "\n",
    "https://www.bilibili.com/video/BV1ce411K7XC?p=15&spm_id_from=pageDriver&vd_source=7cca4a20f2401942703a8c8eff4d7492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21774a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ccec",
   "metadata": {},
   "source": [
    "The type of pooling layers:\n",
    "- Max\n",
    "- Min\n",
    "- Avg\n",
    "- Global Avg(An alternative way for flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5873ab",
   "metadata": {},
   "source": [
    "## Max-pooling\n",
    "\n",
    "*Max-pooling is used much more than average pooling with one exception which is sometimes very deep in the neural network*\n",
    "\n",
    "The formulas to calculate the dimensions of output feature map are:\n",
    "\n",
    "$$W_{out}=\\lfloor\\frac{W_{in}+2p-d\\cdot(f-1)+1}{s}\\rfloor+1$$\n",
    "$$H_{out}=\\lfloor\\frac{H_{in}+2p-d\\cdot(f-1)+1}{s}\\rfloor+1$$\n",
    "\n",
    "- $p$ padding\n",
    "- $f$ kernel_size\n",
    "- $s$ stride\n",
    "- $d$ dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcefb272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 2, 2])\n",
      "tensor([[[0.4148, 0.4937, 0.2084, 0.9672],\n",
      "         [0.1777, 0.1698, 0.9329, 0.7269],\n",
      "         [0.7871, 0.9162, 0.5005, 0.4857],\n",
      "         [0.2629, 0.6887, 0.4815, 0.8897]]])\n",
      "tensor([[[0.4937, 0.9672],\n",
      "         [0.9162, 0.8897]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1)\n",
    "input = torch.rand(4,4)\n",
    "input = torch.unsqueeze(input, dim=0)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb16aa4",
   "metadata": {},
   "source": [
    "## Average-pooling\n",
    "*Average-pooling 可以去除网络中的架构特性， 如 edge，texture等*\n",
    "\n",
    "**注意：average-pooling 没有dilation操作**\n",
    "\n",
    "The formulas to calculate the dimensions of output feature map are:\n",
    "\n",
    "$$W_{out}=\\lfloor\\frac{W_{in}+2p-f}{s}\\rfloor+1$$\n",
    "$$H_{out}=\\lfloor\\frac{H_{in}+2p-f}{s}\\rfloor+1$$\n",
    "\n",
    "- $p$ padding\n",
    "- $f$ kernel_size\n",
    "- $s$ stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fe5d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 2, 2])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1)\n",
    "input = torch.ones(4,4)\n",
    "input = torch.unsqueeze(input, dim=0)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22261ab9",
   "metadata": {},
   "source": [
    "## Global Average Pooling\n",
    "- GAP将每一张feature ma做平均后，变成一个输出节点，可以直接连接SoftMax\n",
    "- GAP主要是在卷积层后，一种可以取代全连接层或者整合feature map的方法\n",
    "- GAP的目的是对整个网络结构上做正则化防止过拟合\n",
    "\n",
    "\n",
    "Pytorch 中没有专门的GAP layer，可以使用如下方式实现：\n",
    "\n",
    "```AdaptiveAvgPool2d((1,1))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c390b4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5])\n",
      "torch.Size([3, 1, 1])\n",
      "tensor([[[1.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[1.]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((1,1))\n",
    "input = torch.ones(3, 5, 5)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11ec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
